#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸ºé—®ç­”å¯¹ç”ŸæˆéŸ³é¢‘æ–‡ä»¶

åŠŸèƒ½ï¼š
1. ä»æ•°æ®åº“è·å–é—®ç­”å¯¹
2. ä½¿ç”¨ edge-tts ä¸ºé—®é¢˜å’Œç­”æ¡ˆç”ŸæˆéŸ³é¢‘
3. ä¿å­˜åˆ°æœ¬åœ°ç›®å½•

ä½¿ç”¨æ–¹æ³•:
  # ç”Ÿæˆæ‰€æœ‰é—®ç­”å¯¹çš„éŸ³é¢‘
  python prepare/qa_audio/1_generate_audio.py
  
  # åªç”ŸæˆæŒ‡å®šåœºæ™¯çš„éŸ³é¢‘
  python prepare/qa_audio/1_generate_audio.py --scenes daily_002 travel_055
  
  # å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼ˆè¦†ç›–å·²æœ‰æ–‡ä»¶ï¼‰
  python prepare/qa_audio/1_generate_audio.py --force
"""

import argparse
import asyncio
import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Any

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
env_path = Path(__file__).parent.parent.parent / ".env.local"
load_dotenv(env_path)

import edge_tts
import psycopg2
from psycopg2.extras import RealDictCursor

# ============================================================
# é…ç½®
# ============================================================

# è¾“å‡ºç›®å½•
OUTPUT_DIR = Path(__file__).parent / "audio"
QUESTIONS_DIR = OUTPUT_DIR / "questions"
RESPONSES_DIR = OUTPUT_DIR / "responses"

# éŸ³è‰²é…ç½®
QUESTION_VOICE = "en-US-AriaNeural"
ANSWER_VOICES = ["en-US-JennyNeural", "en-GB-SoniaNeural", "en-US-DavisNeural"]

# æ•°æ®åº“é…ç½®
DATABASE_URL = os.getenv("DATABASE_URL", "")

# ============================================================
# æ•°æ®åº“æ“ä½œ
# ============================================================

def fetch_qa_pairs(scene_ids: List[str] = None) -> List[Dict[str, Any]]:
    """ä»æ•°æ®åº“è·å–é—®ç­”å¯¹"""
    if not DATABASE_URL:
        print("âŒ é”™è¯¯: è¯·è®¾ç½® DATABASE_URL ç¯å¢ƒå˜é‡")
        sys.exit(1)
    
    conn = psycopg2.connect(DATABASE_URL)
    cursor = conn.cursor(cursor_factory=RealDictCursor)
    
    if scene_ids:
        placeholders = ','.join(['%s'] * len(scene_ids))
        cursor.execute(f"""
            SELECT 
                qp.id, 
                qp.sub_scene_id, 
                qp.speaker_text, 
                qp.speaker_text_cn,
                qp.responses,
                qp.audio_url,
                qp.qa_type,
                ss.scene_id
            FROM qa_pairs qp
            JOIN sub_scenes ss ON qp.sub_scene_id = ss.id
            WHERE ss.scene_id IN ({placeholders})
            ORDER BY ss.scene_id, qp."order"
        """, scene_ids)
    else:
        cursor.execute("""
            SELECT 
                id, 
                sub_scene_id, 
                speaker_text, 
                speaker_text_cn,
                responses,
                audio_url,
                qa_type
            FROM qa_pairs
            ORDER BY sub_scene_id, "order"
        """)
    
    qa_pairs = [dict(row) for row in cursor.fetchall()]
    cursor.close()
    conn.close()
    
    return qa_pairs

# ============================================================
# éŸ³é¢‘ç”Ÿæˆ
# ============================================================

async def generate_audio(text: str, output_path: Path, voice: str, max_retries: int = 3) -> bool:
    """ä½¿ç”¨edge-ttsç”ŸæˆéŸ³é¢‘æ–‡ä»¶"""
    for attempt in range(max_retries):
        try:
            communicate = edge_tts.Communicate(text, voice, rate="+20%")
            await communicate.save(str(output_path))
            
            if output_path.exists() and output_path.stat().st_size > 1024:
                return True
            else:
                print(f"  âš ï¸ ç”Ÿæˆçš„æ–‡ä»¶å¤ªå°æˆ–ä¸ºç©º")
                if output_path.exists():
                    output_path.unlink()
                
        except Exception as e:
            if attempt == max_retries - 1:
                print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")
                return False
            else:
                wait_time = (attempt + 1) * 2
                print(f"  âš ï¸ é‡è¯• {attempt + 1}/{max_retries}ï¼Œç­‰å¾…{wait_time}s")
                await asyncio.sleep(wait_time)
    
    return False

# ============================================================
# ä¸»å¤„ç†é€»è¾‘
# ============================================================

async def process_qa_pair(qa: Dict[str, Any], stats: Dict[str, int], force: bool = False) -> None:
    """å¤„ç†å•ä¸ªé—®ç­”å¯¹"""
    qa_id = qa["id"]
    speaker_text = qa["speaker_text"]
    responses = qa["responses"] or []
    
    print(f"\nğŸ“ å¤„ç†é—®ç­”å¯¹: {qa_id}")
    print(f"   é—®é¢˜: {speaker_text[:50]}...")
    
    # 1. ç”Ÿæˆé—®é¢˜éŸ³é¢‘
    question_audio_path = QUESTIONS_DIR / f"{qa_id}.mp3"
    
    should_generate = force or not question_audio_path.exists() or question_audio_path.stat().st_size <= 1024
    
    if should_generate:
        print(f"  ğŸ™ï¸ ç”Ÿæˆé—®é¢˜éŸ³é¢‘...")
        if await generate_audio(speaker_text, question_audio_path, QUESTION_VOICE):
            stats["questions_success"] += 1
            print(f"  âœ… é—®é¢˜éŸ³é¢‘å®Œæˆ: {question_audio_path.name}")
        else:
            stats["questions_failed"] += 1
    else:
        print(f"  â­ï¸ é—®é¢˜éŸ³é¢‘å·²å­˜åœ¨: {question_audio_path.name}")
        stats["questions_skipped"] += 1
    
    # 2. ç”Ÿæˆç­”æ¡ˆéŸ³é¢‘
    for idx, response in enumerate(responses):
        response_text = response.get("text", "")
        if not response_text:
            continue
        
        response_audio_path = RESPONSES_DIR / f"{qa_id}_response{idx}.mp3"
        
        should_generate = force or not response_audio_path.exists() or response_audio_path.stat().st_size <= 1024
        
        if should_generate:
            answer_voice = ANSWER_VOICES[idx % len(ANSWER_VOICES)]
            print(f"  ğŸ™ï¸ ç”Ÿæˆç­”æ¡ˆ {idx + 1} éŸ³é¢‘...")
            if await generate_audio(response_text, response_audio_path, answer_voice):
                stats["responses_success"] += 1
                print(f"  âœ… ç­”æ¡ˆéŸ³é¢‘å®Œæˆ: {response_audio_path.name}")
            else:
                stats["responses_failed"] += 1
        else:
            stats["responses_skipped"] += 1

async def main():
    parser = argparse.ArgumentParser(description='ä¸ºé—®ç­”å¯¹ç”ŸæˆéŸ³é¢‘æ–‡ä»¶')
    parser.add_argument('--scenes', nargs='+', help='æŒ‡å®šåœºæ™¯IDåˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™å¤„ç†æ‰€æœ‰ï¼‰')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼ˆè¦†ç›–å·²æœ‰æ–‡ä»¶ï¼‰')
    args = parser.parse_args()
    
    print("ğŸµ é—®ç­”å¯¹éŸ³é¢‘ç”Ÿæˆå·¥å…·")
    print("=" * 60)
    if args.scenes:
        print(f"ç›®æ ‡åœºæ™¯: {', '.join(args.scenes)}")
    if args.force:
        print("æ¨¡å¼: å¼ºåˆ¶é‡æ–°ç”Ÿæˆ")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    QUESTIONS_DIR.mkdir(parents=True, exist_ok=True)
    RESPONSES_DIR.mkdir(parents=True, exist_ok=True)
    print(f"\nğŸ“ è¾“å‡ºç›®å½•:")
    print(f"   é—®é¢˜: {QUESTIONS_DIR}")
    print(f"   ç­”æ¡ˆ: {RESPONSES_DIR}")
    
    # è·å–é—®ç­”å¯¹æ•°æ®
    print("\nğŸ“– ä»æ•°æ®åº“è·å–é—®ç­”å¯¹æ•°æ®...")
    qa_pairs = fetch_qa_pairs(args.scenes)
    print(f"   âœ… è·å–åˆ° {len(qa_pairs)} ä¸ªé—®ç­”å¯¹")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "questions_success": 0,
        "questions_failed": 0,
        "questions_skipped": 0,
        "responses_success": 0,
        "responses_failed": 0,
        "responses_skipped": 0,
    }
    
    # å¤„ç†æ¯ä¸ªé—®ç­”å¯¹
    print("\n" + "=" * 60)
    print("ğŸš€ å¼€å§‹ç”ŸæˆéŸ³é¢‘...")
    print("=" * 60)
    
    for qa in qa_pairs:
        await process_qa_pair(qa, stats, args.force)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“Š ç”Ÿæˆç»Ÿè®¡")
    print("=" * 60)
    print(f"   é—®é¢˜éŸ³é¢‘:")
    print(f"      æˆåŠŸ: {stats['questions_success']}")
    print(f"      å¤±è´¥: {stats['questions_failed']}")
    print(f"      è·³è¿‡: {stats['questions_skipped']}")
    print(f"   ç­”æ¡ˆéŸ³é¢‘:")
    print(f"      æˆåŠŸ: {stats['responses_success']}")
    print(f"      å¤±è´¥: {stats['responses_failed']}")
    print(f"      è·³è¿‡: {stats['responses_skipped']}")
    
    print(f"\nğŸ“ éŸ³é¢‘æ–‡ä»¶ä¿å­˜åœ¨: {OUTPUT_DIR}")
    print(f"   ä¸‹ä¸€æ­¥: è¿è¡Œ python prepare/qa_audio/2_upload_to_cos.py ä¸Šä¼ åˆ°COS")

if __name__ == "__main__":
    asyncio.run(main())
