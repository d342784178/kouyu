#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ edge-tts ä¸ºåœºæ™¯æ•°æ®ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
1. è¯»å– scenes_final.json
2. ä¸ºå¯¹è¯å†…å®¹ç”ŸæˆéŸ³é¢‘ï¼ˆæ ¹æ®è§’è‰²è‡ªåŠ¨åˆ†é…éŸ³è‰²ï¼‰
3. ä¸ºè¯æ±‡å†…å®¹ç”ŸæˆéŸ³é¢‘

ä½¿ç”¨æ–¹æ³•:
python prepare/scene/scripts/generate_scene_audio.py
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Any, Set
import edge_tts

# å¯ç”¨éŸ³è‰²åˆ—è¡¨ï¼ˆå¥³å£°å’Œç”·å£°äº¤æ›¿åˆ†é…ï¼‰
AVAILABLE_VOICES = [
    # å¥³å£°
    "en-US-AriaNeural",
    "en-US-JennyNeural",
    "en-GB-SoniaNeural",
    "en-AU-NatashaNeural",
    "en-CA-ClaraNeural",
    # ç”·å£°
    "en-US-GuyNeural",
    "en-US-DavisNeural",
    "en-GB-RyanNeural",
    "en-AU-WilliamNeural",
    "en-CA-LiamNeural",
]

DATA_DIR = Path(__file__).parent.parent / "data"
JSON_FILE = DATA_DIR / "scenes_final.json"
AUDIO_DIR = DATA_DIR / "audio"

DIALOGUES_DIR = AUDIO_DIR / "dialogues"
VOCABULARY_DIR = AUDIO_DIR / "vocabulary"


def get_scene_id(scene: Dict[str, Any]) -> str:
    """è·å–åœºæ™¯IDï¼Œå…¼å®¹ scene_id å’Œ id å­—æ®µ"""
    return scene.get("scene_id") or scene.get("id", "")


def get_scene_name(scene: Dict[str, Any]) -> str:
    """è·å–åœºæ™¯åç§°ï¼Œå…¼å®¹ scene_name å’Œ name å­—æ®µ"""
    return scene.get("scene_name") or scene.get("name", "")


class VoiceAssigner:
    """ä¸ºåœºæ™¯ä¸­çš„è§’è‰²åˆ†é…éŸ³è‰²"""
    
    def __init__(self):
        # æ¯ä¸ªåœºæ™¯ç‹¬ç«‹çš„è§’è‰²åˆ°éŸ³è‰²çš„æ˜ å°„
        self.scene_voice_maps: Dict[str, Dict[str, str]] = {}
    
    def get_speakers_in_scene(self, scene: Dict[str, Any]) -> List[str]:
        """è·å–åœºæ™¯ä¸­æ‰€æœ‰çš„ speaker åˆ—è¡¨ï¼ˆæŒ‰å‡ºç°é¡ºåºï¼‰"""
        speakers = []
        seen = set()
        
        dialogue = scene.get("dialogue", {})
        rounds = dialogue.get("rounds", [])
        
        for round_data in rounds:
            for content in round_data.get("content", []):
                speaker = content.get("speaker", "")
                if speaker and speaker not in seen:
                    speakers.append(speaker)
                    seen.add(speaker)
        
        return speakers
    
    def assign_voices_for_scene(self, scene_id: str, speakers: List[str]) -> Dict[str, str]:
        """ä¸ºåœºæ™¯ä¸­çš„è§’è‰²åˆ†é…éŸ³è‰²"""
        if scene_id in self.scene_voice_maps:
            return self.scene_voice_maps[scene_id]
        
        voice_map = {}
        for i, speaker in enumerate(speakers):
            # è½®æµä½¿ç”¨å¯ç”¨éŸ³è‰²åˆ—è¡¨
            voice_map[speaker] = AVAILABLE_VOICES[i % len(AVAILABLE_VOICES)]
        
        self.scene_voice_maps[scene_id] = voice_map
        return voice_map
    
    def get_voice_for_speaker(self, scene_id: str, speaker: str) -> str:
        """è·å–æŒ‡å®šåœºæ™¯ä¸­è§’è‰²çš„éŸ³è‰²"""
        voice_map = self.scene_voice_maps.get(scene_id, {})
        return voice_map.get(speaker, AVAILABLE_VOICES[0])
    
    def print_scene_voice_assignment(self, scene_id: str, scene_name: str):
        """æ‰“å°åœºæ™¯çš„éŸ³è‰²åˆ†é…æƒ…å†µ"""
        voice_map = self.scene_voice_maps.get(scene_id, {})
        if voice_map:
            print(f"\n  ğŸ­ åœºæ™¯: {scene_id} - {scene_name}")
            for speaker, voice in voice_map.items():
                voice_type = "å¥³å£°" if "Aria" in voice or "Jenny" in voice or "Sonia" in voice or "Natasha" in voice or "Clara" in voice else "ç”·å£°"
                print(f"     {speaker}: {voice} ({voice_type})")


class AudioGenerator:
    def __init__(self):
        self.stats = {
            "total": 0,
            "success": 0,
            "failed": 0,
            "skipped": 0
        }
        self.failed_items: List[str] = []
        self.voice_assigner = VoiceAssigner()

    async def generate_audio(self, text: str, output_path: Path, voice: str = None, max_retries: int = 3) -> bool:
        """ç”Ÿæˆå•ä¸ªéŸ³é¢‘æ–‡ä»¶"""
        voice_to_use = voice or AVAILABLE_VOICES[0]

        for attempt in range(max_retries):
            try:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”éç©ºï¼ˆå¤§äº1KBè®¤ä¸ºæœ‰æ•ˆï¼‰
                if output_path.exists() and output_path.stat().st_size > 1024:
                    print(f"  â­ï¸  è·³è¿‡å·²å­˜åœ¨: {output_path.name} ({output_path.stat().st_size} bytes)")
                    self.stats["skipped"] += 1
                    return True
                elif output_path.exists() and output_path.stat().st_size <= 1024:
                    print(f"  ğŸ”„ é‡æ–°ç”Ÿæˆç©ºæ–‡ä»¶: {output_path.name} (åŸå¤§å°: {output_path.stat().st_size} bytes)")

                # ä½¿ç”¨ +20% è¯­é€Ÿ
                communicate = edge_tts.Communicate(text, voice_to_use, rate="+20%")
                await communicate.save(str(output_path))
                print(f"  âœ… ç”ŸæˆæˆåŠŸ: {output_path.name}")
                self.stats["success"] += 1
                return True
            except Exception as e:
                error_msg = str(e)
                if attempt == max_retries - 1:
                    print(f"  âŒ ç”Ÿæˆå¤±è´¥: {output_path.name} - {error_msg}")
                    self.stats["failed"] += 1
                    self.failed_items.append(f"{output_path.name}: {text}")
                    return False
                else:
                    wait_time = (attempt + 1) * 2
                    print(f"  âš ï¸  é‡è¯• {attempt + 1}/{max_retries}: {output_path.name} - ç­‰å¾…{wait_time}s")
                    await asyncio.sleep(wait_time)
        return False

    def prepare_scene_voices(self, scenes: List[Dict[str, Any]]):
        """ä¸ºæ‰€æœ‰åœºæ™¯é¢„åˆ†é…éŸ³è‰²"""
        print("\nğŸ™ï¸  åˆ†æåœºæ™¯è§’è‰²å¹¶åˆ†é…éŸ³è‰²...\n")
        
        for scene in scenes:
            scene_id = get_scene_id(scene)
            scene_name = get_scene_name(scene)
            
            if not scene_id:
                continue
            
            # è·å–åœºæ™¯ä¸­çš„æ‰€æœ‰è§’è‰²
            speakers = self.voice_assigner.get_speakers_in_scene(scene)
            
            # ä¸ºè§’è‰²åˆ†é…éŸ³è‰²
            self.voice_assigner.assign_voices_for_scene(scene_id, speakers)
            
            # æ‰“å°åˆ†é…ç»“æœ
            self.voice_assigner.print_scene_voice_assignment(scene_id, scene_name)
        
        print()

    async def process_scenes(self, scenes: List[Dict[str, Any]]):
        """å¤„ç†æ‰€æœ‰åœºæ™¯çš„éŸ³é¢‘ç”Ÿæˆ"""
        tasks = []

        for scene in scenes:
            scene_id = get_scene_id(scene)
            if not scene_id:
                print(f"  âš ï¸  è·³è¿‡: åœºæ™¯ç¼ºå°‘ id å­—æ®µ")
                continue

            dialogue = scene.get("dialogue", {})
            rounds = dialogue.get("rounds", [])

            # å¤„ç†å¯¹è¯éŸ³é¢‘
            for round_data in rounds:
                round_number = round_data.get("round_number", 1)
                contents = round_data.get("content", [])

                for content in contents:
                    text = content.get("text", "")
                    speaker = content.get("speaker", "")
                    
                    if text and speaker:
                        audio_path = DIALOGUES_DIR / f"{scene_id}_round{round_number}_{speaker}.mp3"
                        # ä»é¢„åˆ†é…çš„éŸ³è‰²ä¸­è·å–
                        voice = self.voice_assigner.get_voice_for_speaker(scene_id, speaker)
                        self.stats["total"] += 1
                        tasks.append(self.generate_audio(text, audio_path, voice))

            # å¤„ç†è¯æ±‡éŸ³é¢‘ï¼ˆä½¿ç”¨é»˜è®¤éŸ³è‰²ï¼‰
            vocabulary = scene.get("vocabulary", [])
            for vocab_index, vocab in enumerate(vocabulary, start=1):
                # å•è¯éŸ³é¢‘
                word_text = vocab.get("content", "")
                if word_text:
                    word_audio_path = VOCABULARY_DIR / f"{scene_id}_vocab{vocab_index}_word.mp3"
                    self.stats["total"] += 1
                    tasks.append(self.generate_audio(word_text, word_audio_path, AVAILABLE_VOICES[0]))
                
                # ä¾‹å¥éŸ³é¢‘
                example_text = vocab.get("example", "") or vocab.get("example_sentence", "")
                if example_text:
                    example_audio_path = VOCABULARY_DIR / f"{scene_id}_vocab{vocab_index}_example.mp3"
                    self.stats["total"] += 1
                    tasks.append(self.generate_audio(example_text, example_audio_path, AVAILABLE_VOICES[0]))

        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°ä¸º15
        semaphore = asyncio.Semaphore(15)
        
        async def generate_with_semaphore(task):
            async with semaphore:
                return await task
        
        semaphore_tasks = [generate_with_semaphore(task) for task in tasks]
        total_tasks = len(semaphore_tasks)
        completed = 0
        
        results = await asyncio.gather(*semaphore_tasks, return_exceptions=True)
        
        for i, result in enumerate(results):
            completed += 1
            if completed % 50 == 0 or completed == total_tasks:
                print(f"\n  ğŸ“Š è¿›åº¦: {completed}/{total_tasks} ({completed*100//total_tasks}%)")

    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 50)
        print("ğŸ“Š éŸ³é¢‘ç”Ÿæˆç»Ÿè®¡")
        print("=" * 50)
        print(f"   æ€»è®¡: {self.stats['total']}")
        print(f"   æˆåŠŸ: {self.stats['success']}")
        print(f"   è·³è¿‡: {self.stats['skipped']}")
        print(f"   å¤±è´¥: {self.stats['failed']}")

        if self.failed_items:
            print("\nâŒ å¤±è´¥çš„é¡¹ç›®:")
            for item in self.failed_items[:10]:
                print(f"   - {item}")
            if len(self.failed_items) > 10:
                print(f"   ... è¿˜æœ‰ {len(self.failed_items) - 10} ä¸ª")


async def main():
    print("ğŸµ å¼€å§‹ä¸ºåœºæ™¯æ•°æ®ç”ŸæˆéŸ³é¢‘æ–‡ä»¶")
    print("=" * 50)

    if not JSON_FILE.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {JSON_FILE}")
        sys.exit(1)

    with open(JSON_FILE, "r", encoding="utf-8") as f:
        scenes = json.load(f)

    print(f"ğŸ“– è¯»å–äº† {len(scenes)} ä¸ªåœºæ™¯")

    DIALOGUES_DIR.mkdir(parents=True, exist_ok=True)
    VOCABULARY_DIR.mkdir(parents=True, exist_ok=True)

    dialogue_count = sum(
        len(round_data.get("content", []))
        for scene in scenes
        for round_data in scene.get("dialogue", {}).get("rounds", [])
    )
    vocab_count = sum(len(scene.get("vocabulary", [])) * 2 for scene in scenes)
    
    print(f"   å¯¹è¯éŸ³é¢‘: {dialogue_count} ä¸ª")
    print(f"   è¯æ±‡éŸ³é¢‘: {vocab_count} ä¸ª")
    print(f"   æ€»è®¡: {dialogue_count + vocab_count} ä¸ª")

    generator = AudioGenerator()
    
    # é¢„åˆ†é…éŸ³è‰²
    generator.prepare_scene_voices(scenes)
    
    # ç”ŸæˆéŸ³é¢‘
    await generator.process_scenes(scenes)
    generator.print_summary()

    if generator.stats["failed"] > 0:
        sys.exit(1)
    else:
        print("\nâœ¨ æ‰€æœ‰éŸ³é¢‘ç”ŸæˆæˆåŠŸï¼")


if __name__ == "__main__":
    asyncio.run(main())
