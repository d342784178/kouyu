'use client'

/**
 * AIDialogueStage - ç¬¬ä¸‰é˜¶æ®µï¼šAIæ¨¡æ‹Ÿå¯¹è¯
 *
 * åŠŸèƒ½ï¼š
 * - æ°”æ³¡å¯¹è¯æ ·å¼ï¼ˆAIå·¦ä¾§ï¼Œç”¨æˆ·å³ä¾§ï¼‰
 * - åº•éƒ¨å›ºå®šéº¦å…‹é£æŒ‰é’®ï¼ˆæŒ‰ä½è¯´è¯ï¼Œæ¾å¼€å‘é€ï¼‰
 * - 5ç§’è¶…æ—¶æç¤ºé€»è¾‘
 * - QA_Pair å›åº”çŠ¶æ€è®°å½•ï¼ˆfluent/prompted/failedï¼‰
 * - Fluency_Score è®¡ç®—å’Œå±•ç¤º
 * - Speech SDK å¤±è´¥æ—¶é™çº§ä¸ºæ–‡å­—è¾“å…¥æ¡†
 */

import { useState, useEffect, useRef, useCallback } from 'react'
import { motion, AnimatePresence } from 'framer-motion'
import { calculateFluencyScore } from '@/lib/scene-learning/scoring'
import type { QAPair, QAResponse } from '@/types'
import type { QAPairResult, QAPairResultStatus } from '@/lib/scene-learning/scoring'

// ============================================================
// ç±»å‹å®šä¹‰
// ============================================================

interface AIDialogueStageProps {
  subSceneId: string
  /** ä»çˆ¶ç»„ä»¶ä¼ å…¥ï¼Œé¿å…é‡å¤è¯·æ±‚ */
  qaPairs: QAPair[]
  /** è¿›å…¥ä¸‹ä¸€é˜¶æ®µçš„å›è°ƒï¼Œæºå¸¦æµç•…åº¦å¾—åˆ†ã€æœªé€šè¿‡ id åˆ—è¡¨ã€å¯¹è¯å†å² */
  onProceed: (
    fluencyScore: number,
    failedQaIds: string[],
    dialogueHistory: { qaId: string; userText: string; passed: boolean }[]
  ) => void
}

/** å¯¹è¯æ°”æ³¡æ¶ˆæ¯ */
interface ChatMessage {
  id: string
  role: 'ai' | 'user'
  text: string
  /** æ˜¯å¦ä¸ºè¶…æ—¶æç¤ºè¯­ */
  isHint?: boolean
}

/** å½“å‰å½•éŸ³/è¯†åˆ«çŠ¶æ€ */
type RecordingState = 'idle' | 'recording' | 'recognizing' | 'error'

/** å›ç­”ä¸åŒ¹é…æ—¶çš„ç¡®è®¤å¼¹çª—æ•°æ® */
interface RetryPrompt {
  /** AI æç¤ºæ–‡æ¡ˆ */
  hint: string
  /** éœ€è¦æ’¤é”€çš„ç”¨æˆ·æ¶ˆæ¯ id */
  userMsgId: string
}

// ============================================================
// å·¥å…·å‡½æ•°
// ============================================================

/** ç”Ÿæˆå”¯ä¸€æ¶ˆæ¯ id */
function genId() {
  return `msg_${Date.now()}_${Math.random().toString(36).slice(2, 7)}`
}

/** æ£€æŸ¥ Web Speech API æ˜¯å¦å¯ç”¨ */
function isSpeechRecognitionAvailable(): boolean {
  if (typeof window === 'undefined') return false
  return !!(
    (window as unknown as Record<string, unknown>).SpeechRecognition ||
    (window as unknown as Record<string, unknown>).webkitSpeechRecognition
  )
}

// ============================================================
// å­ç»„ä»¶ï¼šAI è¾“å…¥ä¸­æŒ‡ç¤ºå™¨
// ============================================================

function TypingIndicator() {
  return (
    <motion.div 
      initial={{ opacity: 0, y: 10 }}
      animate={{ opacity: 1, y: 0 }}
      className="flex items-end gap-2 mb-4"
    >
      {/* AI å¤´åƒ */}
      <div className="w-8 h-8 rounded-full bg-[#4F7CF0] flex items-center justify-center shrink-0 text-white text-xs font-bold">
        AI
      </div>
      {/* è¾“å…¥ä¸­æ°”æ³¡ */}
      <div className="max-w-[75%]">
        <div className="text-[10px] text-gray-400 mb-1">AI åŠ©æ‰‹</div>
        <div className="bg-[#EEF2FF] rounded-2xl rounded-bl-md px-4 py-3 shadow-sm border border-gray-100">
          <div className="flex items-center space-x-1.5">
            <div className="animate-bounce">
              <div className="w-1.5 h-1.5 bg-[#4F7CF0] rounded-full"></div>
            </div>
            <div className="animate-bounce" style={{ animationDelay: '0.1s' }}>
              <div className="w-1.5 h-1.5 bg-[#4F7CF0] rounded-full"></div>
            </div>
            <div className="animate-bounce" style={{ animationDelay: '0.2s' }}>
              <div className="w-1.5 h-1.5 bg-[#4F7CF0] rounded-full"></div>
            </div>
            <span className="text-xs text-[#4F7CF0] ml-1">AI æ­£åœ¨è¾“å…¥...</span>
          </div>
        </div>
      </div>
    </motion.div>
  )
}

// ============================================================
// å­ç»„ä»¶ï¼šå•æ¡æ°”æ³¡æ¶ˆæ¯
// ============================================================

interface MessageBubbleProps {
  message: ChatMessage
}

function MessageBubble({ message }: MessageBubbleProps) {
  const isAI = message.role === 'ai'

  return (
    <motion.div
      initial={{ opacity: 0, y: 8 }}
      animate={{ opacity: 1, y: 0 }}
      transition={{ duration: 0.2 }}
      className={`flex items-end gap-2 mb-4 ${isAI ? '' : 'flex-row-reverse'}`}
    >
      {/* å¤´åƒ */}
      {isAI ? (
        <div className="w-8 h-8 rounded-full bg-[#4F7CF0] flex items-center justify-center shrink-0 text-white text-xs font-bold">
          AI
        </div>
      ) : (
        <div className="w-8 h-8 rounded-full bg-gradient-to-r from-[#4F7CF0] to-[#7B5FE8] flex items-center justify-center shrink-0 text-white text-xs font-bold">
          æˆ‘
        </div>
      )}

      {/* æ°”æ³¡å®¹å™¨ */}
      <div className="max-w-[75%]">
        {/* è§’è‰²æ ‡ç­¾ */}
        <div className={`text-[10px] mb-1 ${isAI ? 'text-gray-400' : 'text-right text-gray-400'}`}>
          {isAI ? 'AI åŠ©æ‰‹' : 'æˆ‘'}
        </div>
        
        {/* æ°”æ³¡ */}
        <div
          className={`px-4 py-2.5 rounded-2xl text-sm leading-relaxed shadow-sm ${
            isAI
              ? message.isHint
                ? 'bg-[#FFF8EE] border border-[#F59E0B]/20 text-[#92400E] rounded-bl-md'
                : 'bg-white border border-gray-100 text-[#1F2937] rounded-bl-md'
              : 'bg-gradient-to-r from-[#4F7CF0] to-[#7B5FE8] text-white rounded-br-md'
          }`}
        >
          {message.isHint && (
            <span className="text-xs text-[#F59E0B] font-medium block mb-1">ğŸ’¡ æç¤º</span>
          )}
          {message.text}
        </div>
      </div>
    </motion.div>
  )
}

// ============================================================
// å­ç»„ä»¶ï¼šå½•éŸ³æ³¢å½¢åŠ¨ç”»
// ============================================================

function WaveformAnimation() {
  return (
    <div className="flex items-center gap-0.5 h-5">
      {[0, 1, 2, 3, 4].map((i) => (
        <motion.div
          key={i}
          className="w-1 rounded-full bg-white"
          animate={{ height: ['4px', '16px', '4px'] }}
          transition={{
            duration: 0.6,
            repeat: Infinity,
            delay: i * 0.1,
            ease: 'easeInOut',
          }}
        />
      ))}
    </div>
  )
}

// ============================================================
// å­ç»„ä»¶ï¼šå¯¹è¯å®Œæˆå¡ç‰‡ï¼ˆFluency_Score å±•ç¤ºï¼‰
// ============================================================

interface DialogueSummaryProps {
  fluencyScore: number
  results: QAPairResult[]
  qaPairs: QAPair[]
  onProceed: () => void
}

function DialogueSummary({ fluencyScore, results, qaPairs, onProceed }: DialogueSummaryProps) {
  /** çŠ¶æ€å¯¹åº”çš„ä¸­æ–‡æ ‡ç­¾å’Œé¢œè‰² */
  const statusConfig: Record<QAPairResultStatus, { label: string; color: string }> = {
    fluent: { label: 'æµç•…é€šè¿‡', color: 'text-green-600 bg-green-50' },
    prompted: { label: 'æç¤ºåé€šè¿‡', color: 'text-amber-600 bg-amber-50' },
    failed: { label: 'æœªé€šè¿‡', color: 'text-red-500 bg-red-50' },
  }

  return (
    <motion.div
      initial={{ opacity: 0, y: 20 }}
      animate={{ opacity: 1, y: 0 }}
      className="mx-4 my-4 bg-white rounded-card shadow-card border border-gray-100 overflow-hidden"
    >
      {/* å¾—åˆ†å¤´éƒ¨ */}
      <div className="bg-gradient-to-r from-[#4F7CF0] to-[#7B9FF5] px-5 py-5 text-center">
        <p className="text-white/80 text-sm mb-1">å¯¹è¯å®Œæˆï¼æµç•…åº¦å¾—åˆ†</p>
        <div className="text-5xl font-bold text-white mb-1">{fluencyScore}</div>
        <p className="text-white/70 text-xs">/ 100</p>
      </div>

      {/* å„ QA_Pair çŠ¶æ€åˆ—è¡¨ */}
      <div className="px-4 py-3 space-y-2">
        <p className="text-xs font-semibold text-gray-500 uppercase tracking-wide mb-2">å„ç¯èŠ‚è¡¨ç°</p>
        {results.map((result) => {
          const qa = qaPairs.find((q) => q.id === result.qaId)
          const cfg = statusConfig[result.status]
          return (
            <div key={result.qaId} className="flex items-center justify-between gap-2">
              <p className="text-sm text-gray-700 flex-1 truncate">
                {qa?.speakerText ?? result.qaId}
              </p>
              <span className={`text-xs font-medium px-2 py-0.5 rounded-full shrink-0 ${cfg.color}`}>
                {cfg.label}
              </span>
            </div>
          )
        })}
        {results.length === 0 && (
          <p className="text-sm text-gray-400 text-center py-2">æ— éœ€è¯´è¯çš„ç¯èŠ‚</p>
        )}
      </div>

      {/* æ“ä½œæŒ‰é’® */}
      <div className="px-4 pb-4">
        <button
          type="button"
          onClick={onProceed}
          className="w-full py-3 rounded-card bg-[#4F7CF0] text-white text-sm font-semibold shadow-md hover:bg-[#3D6ADE] transition-colors"
        >
          æŸ¥çœ‹è¯¦ç»†åé¦ˆ
        </button>
      </div>
    </motion.div>
  )
}

// ============================================================
// ä¸»ç»„ä»¶ï¼šAIDialogueStage
// ============================================================

export default function AIDialogueStage({
  subSceneId,
  qaPairs,
  onProceed,
}: AIDialogueStageProps) {
  // ---- å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ ----
  const [messages, setMessages] = useState<ChatMessage[]>([])
  // ---- AI æ­£åœ¨è¾“å…¥ä¸­ ----
  const [isAITyping, setIsAITyping] = useState(false)
  // ---- å½“å‰ QA_Pair ç´¢å¼•ï¼ˆ0-basedï¼‰ ----
  const [currentQaIndex, setCurrentQaIndex] = useState(0)
  // ---- å½•éŸ³/è¯†åˆ«çŠ¶æ€ ----
  const [recordingState, setRecordingState] = useState<RecordingState>('idle')
  // ---- æ˜¯å¦é™çº§ä¸ºæ–‡å­—è¾“å…¥ ----
  const [useFallbackInput, setUseFallbackInput] = useState(false)
  // ---- æ–‡å­—è¾“å…¥æ¡†å†…å®¹ ----
  const [textInput, setTextInput] = useState('')
  // ---- å¯¹è¯æ˜¯å¦å·²å®Œæˆ ----
  const [isComplete, setIsComplete] = useState(false)
  // ---- QA_Pair å›åº”ç»“æœåˆ—è¡¨ ----
  const [qaResults, setQaResults] = useState<QAPairResult[]>([])
  // ---- æ¯ä¸ª QA_Pair å¯¹åº”çš„ç”¨æˆ·è¾“å…¥æ–‡æœ¬ï¼ˆç”¨äº ReviewStageï¼‰ ----
  const userTextMapRef = useRef<Map<string, string>>(new Map())
  // ---- å½“å‰ QA_Pair æ˜¯å¦å·²æ”¶åˆ°æç¤ºï¼ˆç”¨äºåˆ¤æ–­ prompted çŠ¶æ€ï¼‰ ----
  const [currentQaHinted, setCurrentQaHinted] = useState(false)
  // ---- Fluency_Score ----
  const [fluencyScore, setFluencyScore] = useState(0)
  // ---- å›ç­”ä¸åŒ¹é…æ—¶çš„ç¡®è®¤å¼¹çª— ----
  const [retryPrompt, setRetryPrompt] = useState<RetryPrompt | null>(null)

  // ---- Refs ----
  const messagesEndRef = useRef<HTMLDivElement>(null)
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const timeoutRef = useRef<ReturnType<typeof setTimeout> | null>(null)
  const conversationHistoryRef = useRef<{ role: 'ai' | 'user'; text: string }[]>([])
  const currentQaHintedRef = useRef(false)
  const currentQaIndexRef = useRef(0)
  const isProcessingRef = useRef(false) // é˜²æ­¢é‡å¤æäº¤

  // ---- åŒæ­¥ ref ä¸ state ----
  useEffect(() => {
    currentQaHintedRef.current = currentQaHinted
  }, [currentQaHinted])

  useEffect(() => {
    currentQaIndexRef.current = currentQaIndex
  }, [currentQaIndex])

  // ---- è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨ ----
  const scrollToBottom = useCallback(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' })
  }, [])

  useEffect(() => {
    scrollToBottom()
  }, [messages, isAITyping, scrollToBottom])

  // ---- æ·»åŠ æ¶ˆæ¯åˆ°åˆ—è¡¨ ----
  const addMessage = useCallback((role: 'ai' | 'user', text: string, isHint = false) => {
    const msg: ChatMessage = { id: genId(), role, text, isHint }
    setMessages((prev) => [...prev, msg])
    conversationHistoryRef.current.push({ role, text })
    return msg
  }, [])

  // ---- æ¸…é™¤è¶…æ—¶è®¡æ—¶å™¨ ----
  const clearTimeoutTimer = useCallback(() => {
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current)
      timeoutRef.current = null
    }
  }, [])

  // ---- è°ƒç”¨ AI å¯¹è¯ API ----
  const callAIDialogue = useCallback(
    async (userMessage: string) => {
      if (isProcessingRef.current) return
      isProcessingRef.current = true
      clearTimeoutTimer()

      try {
        setIsAITyping(true)

        const body = {
          userMessage,
          currentQaIndex: currentQaIndexRef.current,
          conversationHistory: conversationHistoryRef.current,
        }

        const res = await fetch(`/api/sub-scenes/${subSceneId}/ai-dialogue`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(body),
        })

        if (!res.ok) throw new Error('API è¯·æ±‚å¤±è´¥')

        const data = await res.json()
        const { pass, nextQaIndex, aiMessage, isComplete: done, hint } = data

        // è®°å½•å½“å‰ QA_Pair çš„å›åº”çŠ¶æ€ï¼ˆä»…åœ¨é€šè¿‡æ—¶è®°å½•ï¼‰
        const currentQa = qaPairs[currentQaIndexRef.current]
        if (pass && currentQa && currentQa.qaType === 'must_speak') {
          const status: QAPairResultStatus = currentQaHintedRef.current ? 'prompted' : 'fluent'
          userTextMapRef.current.set(currentQa.id, userMessage)
          setQaResults((prev) => {
            const exists = prev.find((r) => r.qaId === currentQa.id)
            if (exists) return prev
            return [...prev, { qaId: currentQa.id, status }]
          })
        }

        // é€šè¿‡åé‡ç½®æç¤ºçŠ¶æ€
        if (pass) {
          setCurrentQaHinted(false)
          currentQaHintedRef.current = false
        }

        setIsAITyping(false)

        // pass: false æ—¶ï¼Œå¼¹å‡ºç¡®è®¤å¼¹çª—ï¼Œç­‰ç”¨æˆ·ç¡®è®¤åæ’¤é”€æ¶ˆæ¯å¹¶é‡æ–°è¾“å…¥
        if (!pass) {
          // ä½¿ç”¨å¤§æ¨¡å‹è¿”å›çš„å…·ä½“æç¤ºä¿¡æ¯ï¼Œæˆ–é»˜è®¤æç¤º
          const hintText = hint || 'å›ç­”ä¸åœºæ™¯ä¸ç¬¦ï¼Œè¯·é‡æ–°å°è¯•'
          // æ‰¾åˆ°åˆšæ‰åŠ å…¥çš„ç”¨æˆ·æ¶ˆæ¯ idï¼ˆæ¶ˆæ¯åˆ—è¡¨æœ€åä¸€æ¡ï¼‰
          setMessages((prev) => {
            const lastUserMsg = [...prev].reverse().find((m) => m.role === 'user')
            if (lastUserMsg) {
              setRetryPrompt({ hint: hintText, userMsgId: lastUserMsg.id })
            }
            return prev
          })
          return
        }

        if (done) {
          setIsComplete(true)
          setCurrentQaIndex(nextQaIndex)
          currentQaIndexRef.current = nextQaIndex
          return
        }

        // æ¨è¿›åˆ°ä¸‹ä¸€ä¸ª QA_Pair
        setCurrentQaIndex(nextQaIndex)
        currentQaIndexRef.current = nextQaIndex

        // AI å‘é€ä¸‹ä¸€æ¡æ¶ˆæ¯
        if (aiMessage) {
          addMessage('ai', aiMessage)
        }
      } catch {
        setIsAITyping(false)
        // API å¤±è´¥æ—¶é™çº§ä¸ºæ–‡å­—è¾“å…¥
        setUseFallbackInput(true)
      } finally {
        isProcessingRef.current = false
      }
    },
    [subSceneId, qaPairs, addMessage, clearTimeoutTimer]
  )

  // ---- è¶…æ—¶æç¤ºé€»è¾‘ï¼ˆ5ç§’æ— è¾“å…¥ï¼ŒAI å‘é€æç¤ºè¯­ï¼‰ ----
  const startTimeoutTimer = useCallback(() => {
    clearTimeoutTimer()
    timeoutRef.current = setTimeout(async () => {
      // æ ‡è®°å½“å‰ QA_Pair å·²æ”¶åˆ°æç¤º
      setCurrentQaHinted(true)
      currentQaHintedRef.current = true

      // é€šè¿‡ API è·å–æç¤ºè¯­ï¼ˆä¼ å…¥ç‰¹æ®Šæ ‡è®°ï¼‰
      try {
        setIsAITyping(true)
        const body = {
          userMessage: '__timeout_hint__',
          currentQaIndex: currentQaIndexRef.current,
          conversationHistory: conversationHistoryRef.current,
        }
        const res = await fetch(`/api/sub-scenes/${subSceneId}/ai-dialogue`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(body),
        })
        setIsAITyping(false)

        if (res.ok) {
          const data = await res.json()
          if (data.aiMessage) {
            addMessage('ai', data.aiMessage, true)
          }
        } else {
          // API å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤æç¤ºè¯­
          addMessage('ai', 'Take your time, what would you say here?', true)
        }
      } catch {
        setIsAITyping(false)
        addMessage('ai', 'Take your time, what would you say here?', true)
      }

      // æç¤ºåå†æ¬¡å¯åŠ¨è®¡æ—¶å™¨
      startTimeoutTimer()
    }, 5000)
  }, [subSceneId, addMessage, clearTimeoutTimer])

  // ---- å¤„ç†ç”¨æˆ·æäº¤ï¼ˆæ–‡å­—æˆ–è¯­éŸ³è¯†åˆ«ç»“æœï¼‰ ----
  const handleUserSubmit = useCallback(
    (text: string) => {
      const trimmed = text.trim()
      if (!trimmed || isProcessingRef.current) return

      clearTimeoutTimer()
      addMessage('user', trimmed)
      setTextInput('')
      callAIDialogue(trimmed)
    },
    [addMessage, callAIDialogue, clearTimeoutTimer]
  )

  // ---- åˆå§‹åŒ–ï¼šAI å‘é€ç¬¬ä¸€æ¡æ¶ˆæ¯ ----
  useEffect(() => {
    if (qaPairs.length === 0) return

    const firstQa = qaPairs[0]
    // ç¨ä½œå»¶è¿Ÿï¼Œè®©ç»„ä»¶æ¸²æŸ“å®Œæˆåå†æ˜¾ç¤ºæ¶ˆæ¯
    const timer = setTimeout(() => {
      addMessage('ai', firstQa.speakerText)
      // ä¸è‡ªåŠ¨å¯åŠ¨è¶…æ—¶è®¡æ—¶å™¨ï¼Œç­‰ç”¨æˆ·å¼€å§‹å½•éŸ³åå†å¯åŠ¨
      // startTimeoutTimer()
    }, 500)

    return () => {
      clearTimeout(timer)
      clearTimeoutTimer()
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []) // ä»…åœ¨æŒ‚è½½æ—¶æ‰§è¡Œä¸€æ¬¡

  // ---- å¯¹è¯å®Œæˆæ—¶è®¡ç®— Fluency_Scoreï¼Œå¹¶è¡¥è®°æœªé€šè¿‡çš„ QA_Pair ----
  useEffect(() => {
    if (!isComplete) return

    // è¡¥è®°æ²¡æœ‰é€šè¿‡è®°å½•çš„ must_speak QA_Pair ä¸º failed
    const mustSpeakQas = qaPairs.filter((q) => q.qaType === 'must_speak')
    setQaResults((prev) => {
      const extra = mustSpeakQas
        .filter((q) => !prev.find((r) => r.qaId === q.id))
        .map((q) => ({ qaId: q.id, status: 'failed' as QAPairResultStatus }))
      return extra.length > 0 ? [...prev, ...extra] : prev
    })

    const mustSpeakCount = mustSpeakQas.length
    const score = calculateFluencyScore(qaResults, mustSpeakCount)
    setFluencyScore(score)
  }, [isComplete, qaResults, qaPairs])

  // ---- ç»„ä»¶å¸è½½æ—¶æ¸…ç†è¶…æ—¶è®¡æ—¶å™¨ ----
  useEffect(() => {
    return () => {
      clearTimeoutTimer()
    }
  }, [clearTimeoutTimer])

  // ---- è¯­éŸ³è¯†åˆ«ç›¸å…³ refs ----
  const finalTranscriptRef = useRef('')
  const interimTranscriptRef = useRef('')
  const silenceTimeoutRef = useRef<ReturnType<typeof setTimeout> | null>(null)
  const handleUserSubmitRef = useRef(handleUserSubmit)
  useEffect(() => { handleUserSubmitRef.current = handleUserSubmit }, [handleUserSubmit])

  // ---- åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«ï¼ˆä¸€æ¬¡æ€§ï¼Œå‚è€ƒ OpenTestDialogï¼‰----
  useEffect(() => {
    const SR = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition
    if (!SR) {
      setUseFallbackInput(true)
      return
    }

    const rec = new SR() as SpeechRecognition
    rec.lang = 'en-US'
    rec.continuous = true
    rec.interimResults = true

    const clearSilence = () => {
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current)
        silenceTimeoutRef.current = null
      }
    }

    const setSilenceTimeout = () => {
      clearSilence()
      silenceTimeoutRef.current = setTimeout(() => {
        const transcript = (finalTranscriptRef.current || interimTranscriptRef.current).trim()
        if (transcript) {
          handleUserSubmitRef.current(transcript)
        } else {
          setRecordingState('idle')
        }
        try { rec.stop() } catch (_) {}
      }, 800)
    }

    rec.onresult = (event: SpeechRecognitionEvent) => {
      let finalText = ''
      let interimText = ''
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const t = event.results[i][0].transcript
        if (event.results[i].isFinal) finalText += t
        else interimText += t
      }
      if (finalText) finalTranscriptRef.current += finalText
      if (interimText) interimTranscriptRef.current = interimText
      // æ¯æ¬¡æœ‰è¯­éŸ³è¾“å…¥å°±é‡ç½® 800ms é™éŸ³è®¡æ—¶å™¨
      setSilenceTimeout()
    }

    rec.onerror = (event: SpeechRecognitionErrorEvent) => {
      clearSilence()
      if (event.error === 'aborted') return
      if (event.error === 'not-allowed' || event.error === 'audio-capture') {
        setUseFallbackInput(true)
        return
      }
      setRecordingState('idle')
    }

    rec.onend = () => {
      clearSilence()
      finalTranscriptRef.current = ''
      interimTranscriptRef.current = ''
      setRecordingState((prev) => (prev === 'recording' ? 'idle' : prev))
    }

    recognitionRef.current = rec

    return () => {
      clearSilence()
      try { rec.abort() } catch (_) {}
    }
  // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [])

  // ---- å¼€å§‹å½•éŸ³ï¼ˆç‚¹å‡»è§¦å‘ï¼‰----
  const startRecording = useCallback(async () => {
    if (isProcessingRef.current || isAITyping || !recognitionRef.current) return

    try {
      // é‡ç½®è½¬å½•å†…å®¹
      finalTranscriptRef.current = ''
      interimTranscriptRef.current = ''
      clearTimeoutTimer()

      // å…ˆè¯·æ±‚éº¦å…‹é£æƒé™
      await navigator.mediaDevices.getUserMedia({ audio: true })

      recognitionRef.current.start()
      setRecordingState('recording')
    } catch {
      setUseFallbackInput(true)
    }
  }, [isAITyping, clearTimeoutTimer])

  // ---- åœæ­¢å½•éŸ³ï¼ˆç‚¹å‡»è§¦å‘ï¼Œæ‰‹åŠ¨åœæ­¢ï¼‰----
  const stopRecording = useCallback(() => {
    if (!recognitionRef.current) return

    // æ¸…é™¤é™éŸ³è®¡æ—¶å™¨
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current)
      silenceTimeoutRef.current = null
    }

    const transcript = (finalTranscriptRef.current || interimTranscriptRef.current).trim()
    if (transcript) {
      handleUserSubmitRef.current(transcript)
    } else {
      setRecordingState('idle')
    }
    try { recognitionRef.current.stop() } catch (_) {}
  }, [])

  // ---- æ–‡å­—è¾“å…¥æ¡†æäº¤ ----
  const handleTextSubmit = useCallback(() => {
    handleUserSubmit(textInput)
  }, [handleUserSubmit, textInput])

  // ---- ç”¨æˆ·ç¡®è®¤"é‡æ–°è¾“å…¥"ï¼šæ’¤é”€ç”¨æˆ·æ¶ˆæ¯å¹¶å…³é—­å¼¹çª— ----
  const handleRetryConfirm = useCallback(() => {
    if (!retryPrompt) return
    const { userMsgId } = retryPrompt

    // ä»æ¶ˆæ¯åˆ—è¡¨ä¸­ç§»é™¤è¯¥ç”¨æˆ·æ¶ˆæ¯
    setMessages((prev) => prev.filter((m) => m.id !== userMsgId))

    // åŒæ­¥æ’¤é”€ conversationHistoryRef ä¸­æœ€åä¸€æ¡ user è®°å½•
    const history = conversationHistoryRef.current
    const lastUserIdx = [...history].map((h, i) => ({ ...h, i })).reverse().find((h) => h.role === 'user')?.i
    if (lastUserIdx !== undefined) {
      conversationHistoryRef.current = history.filter((_, i) => i !== lastUserIdx)
    }

    setRetryPrompt(null)
  }, [retryPrompt])

  // ---- å¯¹è¯å®Œæˆåçš„ onProceed å›è°ƒ ----
  const handleProceed = useCallback(() => {
    const failedQaIds = qaResults
      .filter((r) => r.status === 'failed')
      .map((r) => r.qaId)

    // æ„å»ºå¯¹è¯å†å²ï¼ˆä¾› ReviewStage ä½¿ç”¨ï¼‰
    const dialogueHistory = qaResults.map((r) => ({
      qaId: r.qaId,
      userText: userTextMapRef.current.get(r.qaId) ?? '',
      passed: r.status !== 'failed',
    }))

    onProceed(fluencyScore, failedQaIds, dialogueHistory)
  }, [qaResults, fluencyScore, onProceed])

  // ============================================================
  // æ¸²æŸ“
  // ============================================================

  return (
    <div style={{ flex: 1, display: 'flex', flexDirection: 'column', minHeight: 0 }} className="bg-white relative">

      {/* ---- æ¶ˆæ¯åˆ—è¡¨åŒºåŸŸï¼ˆå¯æ»šåŠ¨ï¼Œç™½è‰²èƒŒæ™¯ï¼‰ ---- */}
      <div className="flex-1 overflow-y-auto px-4 py-4 space-y-4">
        {messages.length === 0 ? (
          <div className="flex items-center justify-center h-32 text-[#6B7280] text-sm">
            ç­‰å¾…å¯¹è¯å¼€å§‹...
          </div>
        ) : (
          <>
            {messages.map((msg) => (
              <MessageBubble key={msg.id} message={msg} />
            ))}
            {isAITyping && <TypingIndicator />}
            {isComplete && (
              <DialogueSummary
                fluencyScore={fluencyScore}
                results={qaResults}
                qaPairs={qaPairs}
                onProceed={handleProceed}
              />
            )}
            <div ref={messagesEndRef} />
          </>
        )}
      </div>

      {/* ---- å›ç­”ä¸åŒ¹é…ç¡®è®¤å¼¹çª— ---- */}
      <AnimatePresence>
        {retryPrompt && (
          <motion.div
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            exit={{ opacity: 0 }}
            className="absolute inset-0 z-20 flex items-end justify-center bg-black/40 pb-6 px-4"
          >
            <motion.div
              initial={{ y: 40, opacity: 0 }}
              animate={{ y: 0, opacity: 1 }}
              exit={{ y: 40, opacity: 0 }}
              transition={{ type: 'spring', damping: 20, stiffness: 300 }}
              className="w-full max-w-sm bg-white rounded-2xl shadow-xl overflow-hidden"
            >
              <div className="px-5 pt-5 pb-3 flex items-start gap-3">
                <div className="w-9 h-9 rounded-full bg-amber-100 flex items-center justify-center shrink-0 mt-0.5">
                  <span className="text-lg">ğŸ’¬</span>
                </div>
                <div>
                  <p className="text-sm font-semibold text-[#1F2937] mb-1">å›ç­”ä¸åœºæ™¯ä¸ç¬¦</p>
                  <p className="text-sm text-[#6B7280] leading-relaxed">{retryPrompt.hint}</p>
                </div>
              </div>
              <div className="h-px bg-gray-100 mx-5" />
              <div className="px-5 py-4">
                <button
                  type="button"
                  onClick={handleRetryConfirm}
                  className="w-full h-11 rounded-full bg-gradient-to-r from-[#4F7CF0] to-[#7B5FE8] text-white text-sm font-semibold shadow-md"
                >
                  å¥½çš„ï¼Œé‡æ–°è¾“å…¥
                </button>
              </div>
            </motion.div>
          </motion.div>
        )}
      </AnimatePresence>

      {/* ---- åº•éƒ¨è¾“å…¥åŒºåŸŸ ---- */}
      {!isComplete && (
        <div className="shrink-0 border-t border-gray-100 bg-white px-4 py-3 pb-safe">

          {/* æ–‡å­—è¾“å…¥æ¨¡å¼ */}
          {useFallbackInput ? (
            <div className="flex items-center gap-2">
              <input
                type="text"
                value={textInput}
                onChange={(e) => setTextInput(e.target.value)}
                onKeyDown={(e) => {
                  if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault()
                    handleTextSubmit()
                  }
                }}
                placeholder="è¯·è¾“å…¥è‹±æ–‡å›å¤..."
                disabled={isAITyping || isProcessingRef.current}
                className="flex-1 h-11 px-4 rounded-full border border-gray-200 text-sm focus:outline-none focus:border-[#4F7CF0] focus:ring-2 focus:ring-[#4F7CF0]/20 disabled:opacity-50 bg-gray-50"
              />
              <button
                type="button"
                onClick={handleTextSubmit}
                disabled={!textInput.trim() || isAITyping}
                className="h-11 w-11 rounded-full bg-gradient-to-r from-[#4F7CF0] to-[#7B5FE8] text-white flex items-center justify-center shrink-0 disabled:opacity-40"
                aria-label="å‘é€"
              >
                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2.5" strokeLinecap="round" strokeLinejoin="round">
                  <line x1="22" y1="2" x2="11" y2="13" /><polygon points="22 2 15 22 11 13 2 9 22 2" />
                </svg>
              </button>
              {isSpeechRecognitionAvailable() && (
                <button
                  type="button"
                  onClick={() => setUseFallbackInput(false)}
                  className="h-11 w-11 bg-gray-100 text-gray-600 rounded-full flex items-center justify-center hover:bg-gray-200 transition-colors"
                >
                  <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                    <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z" />
                    <path d="M19 10v2a7 7 0 0 1-14 0v-2" />
                    <line x1="12" y1="19" x2="12" y2="23" /><line x1="8" y1="23" x2="16" y2="23" />
                  </svg>
                </button>
              )}
            </div>
          ) : (
            /* è¯­éŸ³æ¨¡å¼ï¼šå®½æ¡å½¢æŒ‰é’®ï¼ˆä¸ OpenDialogue ä¸€è‡´ï¼‰ */
            <div className="flex items-center gap-2">
              <button
                type="button"
                onClick={recordingState === 'recording' ? stopRecording : startRecording}
                disabled={isAITyping || isProcessingRef.current}
                aria-label={recordingState === 'recording' ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å½•éŸ³'}
                className={`flex-1 h-12 rounded-full font-semibold text-sm transition-all shadow-md flex items-center justify-center gap-2 select-none ${
                  recordingState === 'recording'
                    ? 'bg-[#EF4444] text-white shadow-lg shadow-red-200'
                    : isAITyping || isProcessingRef.current
                    ? 'bg-gray-200 text-gray-400 cursor-not-allowed shadow-none'
                    : 'bg-gradient-to-r from-[#4F7CF0] to-[#7B5FE8] text-white hover:shadow-lg'
                }`}
              >
                {recordingState === 'recording' ? (
                  <><WaveformAnimation /><span>åœæ­¢å½•éŸ³</span></>
                ) : isAITyping ? (
                  <>
                    <svg className="animate-spin" width="18" height="18" viewBox="0 0 24 24" fill="none">
                      <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="3" />
                      <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4z" />
                    </svg>
                    <span>AI æ€è€ƒä¸­...</span>
                  </>
                ) : (
                  <>
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                      <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z" />
                      <path d="M19 10v2a7 7 0 0 1-14 0v-2" />
                      <line x1="12" y1="19" x2="12" y2="23" /><line x1="8" y1="23" x2="16" y2="23" />
                    </svg>
                    <span>å¼€å§‹å½•éŸ³</span>
                  </>
                )}
              </button>

              {/* åˆ‡æ¢æ–‡å­—è¾“å…¥ */}
              <button
                type="button"
                onClick={() => setUseFallbackInput(true)}
                disabled={isAITyping}
                className="h-12 w-12 bg-gray-100 text-gray-600 rounded-full flex items-center justify-center hover:bg-gray-200 transition-colors disabled:opacity-40"
              >
                <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                  <polyline points="4 7 4 4 20 4 20 7" /><line x1="9" y1="20" x2="15" y2="20" /><line x1="12" y1="4" x2="12" y2="20" />
                </svg>
              </button>
            </div>
          )}
        </div>
      )}
    </div>
  )
}
