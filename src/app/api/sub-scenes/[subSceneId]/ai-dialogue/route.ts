import { NextRequest, NextResponse } from 'next/server'
import { getSubSceneById, getQAPairsBySubSceneId } from '@/lib/db/sub-scenes'
import { callLLMForScene } from '@/lib/llm'
import type { AIDialogueRequest, AIDialogueResponse, QAResponse } from '@/types'

// ç¦ç”¨ Next.js æ•°æ®ç¼“å­˜
export const dynamic = 'force-dynamic'
export const revalidate = 0

/**
 * POST /api/sub-scenes/[subSceneId]/ai-dialogue
 * è°ƒç”¨å¤§æ¨¡å‹åˆ¤æ–­ç”¨æˆ·å›åº”æ˜¯å¦è¯­ä¹‰åŒ¹é…å½“å‰ QA_Pairï¼Œå¹¶æ¨è¿›å¯¹è¯
 * ä½¿ç”¨æ¨¡å‹: nvidia/qwen/qwen3-next-80b-a3b-instruct (æµ‹è¯„æ¨¡å‹)
 */
export async function POST(
  request: NextRequest,
  { params }: { params: { subSceneId: string } }
) {
  const { subSceneId } = params

  try {
    // è§£æè¯·æ±‚ä½“
    const body: AIDialogueRequest = await request.json()
    const { userMessage, currentQaIndex, conversationHistory } = body

    // è·å–å­åœºæ™¯ä¿¡æ¯
    const subScene = await getSubSceneById(subSceneId)
    if (!subScene) {
      return NextResponse.json({ error: 'Sub-scene not found' }, { status: 404 })
    }

    // è·å–è¯¥å­åœºæ™¯ä¸‹æ‰€æœ‰é—®ç­”å¯¹
    const qaPairs = await getQAPairsBySubSceneId(subSceneId)
    if (qaPairs.length === 0) {
      return NextResponse.json({ error: 'No QA pairs found' }, { status: 404 })
    }

    // è¾¹ç•Œæ£€æŸ¥ï¼šç¡®ä¿ currentQaIndex åˆæ³•
    if (currentQaIndex < 0 || currentQaIndex >= qaPairs.length) {
      return NextResponse.json({ error: 'Invalid QA index' }, { status: 400 })
    }

    const currentQa = qaPairs[currentQaIndex]

    // è§£æå½“å‰ QA_Pair çš„æ‰€æœ‰åˆæ³•å›åº”
    const responses: QAResponse[] = Array.isArray(currentQa.responses)
      ? (currentQa.responses as QAResponse[])
      : []

    // æ„å»ºå‚è€ƒå›åº”åˆ—è¡¨æ–‡æœ¬
    const responseOptions = responses
      .map((r, i) => `${i + 1}. ${r.text}ï¼ˆ${r.text_cn}ï¼‰`)
      .join('\n')

    // æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘5æ¡ï¼Œé¿å… token è¿‡å¤šï¼‰
    const recentHistory = conversationHistory.slice(-5)
    const historyText = recentHistory
      .map(msg => `${msg.role === 'ai' ? 'AI' : 'ç”¨æˆ·'}: ${msg.text}`)
      .join('\n')

    // è°ƒç”¨æµ‹è¯„æ¨¡å‹è¿›è¡Œè¯­ä¹‰åˆ¤æ–­
    const messages = [
      {
        role: 'system' as const,
        content: `ä½ æ˜¯è‹±è¯­å£è¯­åœºæ™¯ç»ƒä¹ åŠ©æ‰‹ã€‚å½“å‰åœºæ™¯ï¼š${subScene.name}ã€‚
è¯·åˆ¤æ–­ç”¨æˆ·çš„å›åº”æ˜¯å¦ç¬¦åˆå½“å‰åœºæ™¯çš„è¯­ä¹‰è¦æ±‚ã€‚
ä½ éœ€è¦è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
  "pass": true/false,  // ç”¨æˆ·å›åº”æ˜¯å¦è¯­ä¹‰åŒ¹é…
  "reason": "ç®€çŸ­è¯´æ˜åˆ¤æ–­ç†ç”±ï¼ˆä¸­æ–‡ï¼Œ20å­—ä»¥å†…ï¼‰",
  "hint": "å½“passä¸ºfalseæ—¶ï¼Œç»™å‡ºå…·ä½“çš„æç¤ºä¿¡æ¯ï¼ˆä¸­æ–‡ï¼Œå‘Šè¯‰ç”¨æˆ·åº”è¯¥å¦‚ä½•å›åº”ï¼Œ30å­—ä»¥å†…ï¼‰"
}
åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚`,
      },
      {
        role: 'user' as const,
        content: `åœºæ™¯å¯¹è¯å†å²ï¼š
${historyText || 'ï¼ˆå¯¹è¯åˆšå¼€å§‹ï¼‰'}

å½“å‰å¯¹æ–¹è¯´çš„è¯ï¼š${currentQa.speakerText}ï¼ˆ${currentQa.speakerTextCn}ï¼‰

å‚è€ƒå›åº”ï¼ˆä»¥ä¸‹ä»»æ„ä¸€ç§è¯­ä¹‰å‡è§†ä¸ºé€šè¿‡ï¼‰ï¼š
${responseOptions}

ç”¨æˆ·å®é™…å›åº”ï¼š${userMessage}

è¯·åˆ¤æ–­ç”¨æˆ·å›åº”æ˜¯å¦è¯­ä¹‰åŒ¹é…ã€‚å¦‚æœä¸åŒ¹é…ï¼Œè¯·ç»™å‡ºå…·ä½“çš„æç¤ºä¿¡æ¯ã€‚`,
      },
    ]

    const llmResult = await callLLMForScene('question-evaluation', messages, 0.3, 300)

    // è§£æ LLM è¿”å›çš„ JSON
    let pass = false
    let hint: string | undefined
    let reason: string | undefined
    try {
      // æå– JSON å†…å®¹ï¼ˆé˜²æ­¢ LLM è¿”å›å¤šä½™æ–‡å­—ï¼‰
      const jsonMatch = llmResult.content.match(/\{[\s\S]*\}/)
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0])
        pass = Boolean(parsed.pass)
        hint = parsed.hint
        reason = parsed.reason
      }
    } catch {
      console.warn('[ai-dialogue] LLM è¿”å›å†…å®¹è§£æå¤±è´¥ï¼Œé»˜è®¤ pass=false:', llmResult.content)
    }

    // è®¡ç®—ä¸‹ä¸€ä¸ª QA ç´¢å¼•
    const nextQaIndex = pass ? currentQaIndex + 1 : currentQaIndex
    const isComplete = pass && nextQaIndex >= qaPairs.length

    // è‹¥é€šè¿‡ä¸”è¿˜æœ‰ä¸‹ä¸€æ¡ï¼Œè¿”å›ä¸‹ä¸€æ¡ speaker_text ä½œä¸º AI æ¶ˆæ¯
    let aiMessage: string | undefined
    if (!pass) {
      // æœªé€šè¿‡ï¼šç»™å‡ºæç¤ºï¼Œè®©ç”¨æˆ·é‡æ–°è¾“å…¥
      aiMessage = "Hmm, that doesn't quite fit. Try again â€” what would you say here?"
    } else if (pass && !isComplete && nextQaIndex < qaPairs.length) {
      aiMessage = qaPairs[nextQaIndex].speakerText
    } else if (isComplete) {
      aiMessage = "Great job! You've completed this scene. ğŸ‰"
    }

    const response: AIDialogueResponse = {
      pass,
      nextQaIndex,
      aiMessage,
      isComplete,
      hint: !pass ? hint : undefined,
      reason: !pass ? reason : undefined,
    }

    return NextResponse.json(response, { status: 200 })
  } catch (error) {
    console.error(`[POST /api/sub-scenes/${subSceneId}/ai-dialogue] å¤„ç†å¤±è´¥:`, error)
    return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
  }
}
