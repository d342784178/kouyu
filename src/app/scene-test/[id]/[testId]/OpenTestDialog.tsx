'use client'

import { useState, useEffect, useRef, useCallback } from 'react'
import { AnimatePresence } from 'framer-motion'
import TestAnalysis from './TestAnalysis'
import LoadingSpinner from './components/LoadingSpinner'
import {
  AnalyzingView,
  RoleSelectionView,
  InitializingView,
  ActiveChatView,
  CompletedView,
  Message,
  TestStatus,
  QuestionAnalysis,
  DifficultyLevel,
  OpenTestDialogProps
} from '../../components/open-test'

export default function OpenTestDialog({
  sceneId,
  testId,
  testQuestion,
  currentIndex,
  totalTests,
  onComplete,
  autoStart = false
}: OpenTestDialogProps) {
  // çŠ¶æ€ç®¡ç†
  const [status, setStatus] = useState<TestStatus>('idle')
  const [messages, setMessages] = useState<Message[]>([])
  const [currentRound, setCurrentRound] = useState(0)
  const [maxRounds] = useState(5)
  const [isRecording, setIsRecording] = useState(false)
  const [playingMessageIndex, setPlayingMessageIndex] = useState<number | null>(null)
  const [recognition, setRecognition] = useState<any>(null)
  const [audioElement, setAudioElement] = useState<HTMLAudioElement | null>(null)
  const [loading, setLoading] = useState(false)
  const [isGeneratingResponse, setIsGeneratingResponse] = useState(false)
  const [error, setError] = useState<string>('')
  const [showAnalysis, setShowAnalysis] = useState(false)

  // æ–°å¢çŠ¶æ€
  const [questionAnalysis, setQuestionAnalysis] = useState<QuestionAnalysis | null>(null)
  const [selectedRole, setSelectedRole] = useState<string>('')
  const [difficultyLevel, setDifficultyLevel] = useState<DifficultyLevel>('medium')
  const [voiceEnabled, setVoiceEnabled] = useState<boolean>(true)

  // ä½¿ç”¨ ref æ¥å­˜å‚¨æœ€æ–°çš„çŠ¶æ€ï¼Œé¿å…é—­åŒ…é—®é¢˜
  const messagesRef = useRef<Message[]>([])
  const currentRoundRef = useRef<number>(0)

  // åŒæ­¥çŠ¶æ€åˆ° ref
  useEffect(() => {
    messagesRef.current = messages
  }, [messages])

  useEffect(() => {
    currentRoundRef.current = currentRound
  }, [currentRound])

  const messagesEndRef = useRef<HTMLDivElement>(null)

  // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
  useEffect(() => {
    if ('webkitSpeechRecognition' in window) {
      const SpeechRecognition = (window as any).webkitSpeechRecognition
      const recognition = new SpeechRecognition()
      recognition.continuous = false
      recognition.interimResults = false
      recognition.lang = 'en-US'

      recognition.onresult = (event: any) => {
        const transcript = event.results[0][0].transcript
        handleVoiceInput(transcript)
      }

      recognition.onerror = (event: any) => {
        console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error)
        setError('è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•')
        setIsRecording(false)
      }

      recognition.onend = () => {
        setIsRecording(false)
      }

      setRecognition(recognition)
    }
  }, [])

  // æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' })
  }, [messages])

  // è‡ªåŠ¨å¼€å§‹åˆ†æï¼ˆå¦‚æœè®¾ç½®äº†autoStartï¼‰
  useEffect(() => {
    if (autoStart && testQuestion && status === 'idle') {
      console.log('[OpenTestDialog] è‡ªåŠ¨å¼€å§‹åˆ†æé¢˜ç›®')
      analyzeQuestion()
    }
  }, [autoStart, testQuestion])

  // åˆ†ææµ‹è¯•é¢˜ç›®
  const analyzeQuestion = async () => {
    setStatus('analyzing')
    setError('')

    try {
      console.log('å¼€å§‹åˆ†ææµ‹è¯•é¢˜ç›®:', testQuestion)

      const analysisRequest = {
        topic: testQuestion,
        sceneId: sceneId,
        testId: testId
      }

      console.log('é¢˜ç›®åˆ†æè¯·æ±‚:', JSON.stringify(analysisRequest, null, 2))

      const response = await fetch('/api/open-test/analyze', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(analysisRequest),
      })

      const data = await response.json()
      console.log('é¢˜ç›®åˆ†æå“åº”:', JSON.stringify(data, null, 2))

      if (!response.ok) {
        throw new Error(data.error || 'é¢˜ç›®åˆ†æå¤±è´¥')
      }

      const analysisResult: QuestionAnalysis = {
        sceneType: data.sceneType || data.scene || 'ç¤¾äº¤ä¼šé¢',
        sceneDescription: data.sceneDescription || data.description || 'ä½ åœ¨ä¸€å®¶å’–å•¡å…å¶é‡äº†ä¸€ä½å¤–å›½æœ‹å‹ï¼Œè¿™æ˜¯ç»ƒä¹ è‹±è¯­è‡ªæˆ‘ä»‹ç»çš„ç»ä½³æœºä¼šï¼',
        aiRole: data.aiRole || { 
          id: 'ai', 
          name: 'Alex', 
          description: 'æ¥è‡ªç¾å›½çš„æ´»æ³¼å¤–å›½äººï¼Œä¸»åŠ¨ä¸ä½ æ­è¯', 
          emoji: 'ğŸ‡ºğŸ‡¸' 
        },
        userRoles: data.userRoles || data.roles?.map((r: string, i: number) => ({ 
          id: `role_${i}`, 
          name: r, 
          description: 'é€‰æ‹©æ­¤è§’è‰²è¿›è¡Œå¯¹è¯', 
          emoji: 'ğŸ™‹' 
        })) || [{ 
          id: 'user', 
          name: 'ä½ è‡ªå·±', 
          description: 'ç”¨è‹±è¯­è‡ªç„¶åœ°ä»‹ç»è‡ªå·±', 
          emoji: 'ğŸ™‹' 
        }],
        dialogueGoal: data.dialogueGoal || 'å®Œæˆè‡ªæˆ‘ä»‹ç»ï¼šåˆ†äº«ä½ çš„åå­—ã€æ¥è‡ªå“ªé‡Œï¼Œä»¥åŠè‡³å°‘ä¸€ä¸ªä¸ªäººå…´è¶£æˆ–ä¿¡æ¯',
        suggestedTopics: data.suggestedTopics || ['æ—¥å¸¸è¯é¢˜', 'å…´è¶£çˆ±å¥½', 'å·¥ä½œå­¦ä¹ ']
      }

      console.log('è§£æçš„é¢˜ç›®åˆ†æç»“æœ:', analysisResult)

      setQuestionAnalysis(analysisResult)
      setStatus('role-selection')
    } catch (err) {
      console.error('é¢˜ç›®åˆ†æå¤±è´¥:', err)
      const errorMessage = err instanceof Error ? err.message : 'é¢˜ç›®åˆ†æå¤±è´¥ï¼Œè¯·é‡è¯•'
      alert(`GLM APIè°ƒç”¨å¤±è´¥: ${errorMessage}`)
      setError(errorMessage)
      setStatus('idle')
    }
  }

  // ç¡®è®¤è§’è‰²å’Œéš¾åº¦ç­‰çº§ï¼Œå¼€å§‹å¯¹è¯
  const confirmRoleAndDifficulty = async () => {
    if (!selectedRole) {
      setError('è¯·é€‰æ‹©ä¸€ä¸ªè§’è‰²')
      return
    }

    setStatus('initializing')
    setError('')

    try {
      console.log('ç¡®è®¤è§’è‰²å’Œéš¾åº¦ç­‰çº§:', {
        selectedRole,
        difficultyLevel,
        questionAnalysis
      })

      // æ ¹æ®é€‰ä¸­çš„è§’è‰²IDæ‰¾åˆ°å¯¹åº”çš„è§’è‰²åç§°
      const selectedUserRole = questionAnalysis?.userRoles?.find(role => role.id === selectedRole)
      const userRoleName = selectedUserRole?.name || selectedRole
      
      const initRequest = {
        sceneId,
        testId,
        scene: questionAnalysis?.sceneType,
        aiRole: questionAnalysis?.aiRole?.name,
        userRole: userRoleName,
        dialogueGoal: questionAnalysis?.dialogueGoal,
        difficultyLevel
      }

      console.log('åˆå§‹åŒ–å¯¹è¯è¯·æ±‚:', JSON.stringify(initRequest, null, 2))

      const response = await fetch('/api/open-test/initiate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(initRequest),
      })

      const data = await response.json()
      console.log('åˆå§‹åŒ–å¯¹è¯å“åº”:', JSON.stringify(data, null, 2))

      if (!response.ok) {
        throw new Error(data.error || 'åˆå§‹åŒ–å¯¹è¯å¤±è´¥')
      }

      const initialMessage: Message = {
        role: 'assistant',
        content: data.message,
        audioUrl: data.audioUrl,
        timestamp: Date.now(),
      }

      console.log('ç”Ÿæˆçš„åˆå§‹æ¶ˆæ¯:', initialMessage)

      setMessages([initialMessage])
      setCurrentRound(1)
      setStatus('active')

      if (initialMessage.audioUrl) {
        console.log('è‡ªåŠ¨æ’­æ”¾åˆå§‹è¯­éŸ³:', initialMessage.audioUrl)
        setTimeout(() => {
          playAudio(initialMessage.audioUrl!, 0)
        }, 500)
      }
    } catch (err) {
      console.error('åˆå§‹åŒ–å¯¹è¯å¤±è´¥:', err)
      const errorMessage = err instanceof Error ? err.message : 'åˆå§‹åŒ–å¯¹è¯å¤±è´¥ï¼Œè¯·é‡è¯•'
      alert(`GLM APIè°ƒç”¨å¤±è´¥: ${errorMessage}`)
      setError(errorMessage)
      setStatus('role-selection')
    }
  }

  // ç”ŸæˆåŠ©æ‰‹æ¶ˆæ¯ï¼ˆç»§ç»­å¯¹è¯ï¼‰
  const generateAssistantMessage = async (
    prompt: string,
    conversationHistory: Message[],
    round: number
  ): Promise<{ message: Message; isEnd: boolean; isComplete?: boolean }> => {
    setLoading(true)

    try {
      console.log('=== å¼€å§‹ç”ŸæˆåŠ©æ‰‹æ¶ˆæ¯ï¼ˆç»§ç»­å¯¹è¯ï¼‰===')
      console.log('ç”¨æˆ·è¾“å…¥:', prompt)
      console.log('å®Œæ•´å¯¹è¯å†å²:', conversationHistory)
      console.log('å½“å‰è½®æ•°:', round)

      const updatedHistory = conversationHistory.map(msg => ({
        role: msg.role,
        content: msg.content
      }))

      const apiRequest = {
        sceneId,
        testId,
        conversation: updatedHistory,
        round,
        maxRounds,
        scene: questionAnalysis?.sceneType || 'é¤å…',
        aiRole: questionAnalysis?.aiRole?.name || 'æœåŠ¡å‘˜',
        userRole: selectedRole || 'é¡¾å®¢',
        dialogueGoal: questionAnalysis?.dialogueGoal || 'é¡¾å®¢ç‚¹é¤',
        difficultyLevel
      }

      console.log('API è¯·æ±‚å‚æ•°:', JSON.stringify(apiRequest, null, 2))

      const response = await fetch('/api/open-test/continue', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(apiRequest),
      })

      const data = await response.json()
      console.log('API å“åº”çŠ¶æ€:', response.status)
      console.log('API å“åº”æ•°æ®:', JSON.stringify(data, null, 2))

      if (!response.ok) {
        console.error('å¤§æ¨¡å‹ API è°ƒç”¨å¤±è´¥:', data)
        throw new Error(data.error || 'å¤§æ¨¡å‹ API è°ƒç”¨å¤±è´¥')
      }

      const assistantMessage = {
        role: 'assistant' as const,
        content: data.message,
        audioUrl: data.audioUrl,
        timestamp: Date.now(),
      }

      console.log('ç”Ÿæˆçš„åŠ©æ‰‹æ¶ˆæ¯:', assistantMessage)
      console.log('æ˜¯å¦ç»“æŸå¯¹è¯:', data.isEnd || false)
      console.log('å¯¹è¯æ˜¯å¦å·²å®Œæˆ:', data.isComplete || false)

      return {
        message: assistantMessage,
        isEnd: data.isEnd || false,
        isComplete: data.isComplete || false
      }
    } catch (err) {
      console.error('ç”ŸæˆåŠ©æ‰‹æ¶ˆæ¯å¤±è´¥:', err)
      throw err
    } finally {
      setLoading(false)
      console.log('=== ç”ŸæˆåŠ©æ‰‹æ¶ˆæ¯å®Œæˆ ===')
    }
  }

  // å¤„ç†è¯­éŸ³è¾“å…¥
  const handleVoiceInput = async (transcript: string) => {
    if (!transcript.trim()) return

    const currentMessages = messagesRef.current
    const currentRoundValue = currentRoundRef.current

    console.log('=== å¼€å§‹å¤„ç†è¯­éŸ³è¾“å…¥ ===')
    console.log('å½“å‰æ¶ˆæ¯çŠ¶æ€:', currentMessages)
    console.log('ç”¨æˆ·è¾“å…¥:', transcript)
    console.log('å½“å‰è½®æ•°:', currentRoundValue)

    const userMessage: Message = {
      role: 'user',
      content: transcript,
      timestamp: Date.now(),
    }

    const updatedMessages = [...currentMessages, userMessage]
    setMessages(updatedMessages)
    console.log('æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åçš„å¯¹è¯å†å²:', updatedMessages)

    setIsGeneratingResponse(true)

    try {
      console.log('è°ƒç”¨generateAssistantMessageï¼Œä½¿ç”¨å®Œæ•´å¯¹è¯å†å²')
      const nextRound = currentRoundValue + 1
      console.log('ä¼ é€’çš„è½®æ•°:', nextRound)
      const { message: assistantMessage, isEnd, isComplete } = await generateAssistantMessage(
        transcript,
        updatedMessages,
        nextRound
      )
      console.log('æ”¶åˆ°åŠ©æ‰‹æ¶ˆæ¯:', assistantMessage)
      console.log('å¯¹è¯å®ŒæˆçŠ¶æ€:', isComplete)

      const completeHistory = [...updatedMessages, assistantMessage]
      console.log('æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åçš„å®Œæ•´å¯¹è¯å†å²:', completeHistory)

      setMessages(completeHistory)
      console.log('æ›´æ–°è½®æ•°:', nextRound)
      setCurrentRound(nextRound)

      if (assistantMessage.audioUrl) {
        console.log('è‡ªåŠ¨æ’­æ”¾AIè¯­éŸ³:', assistantMessage.audioUrl)
        setTimeout(() => {
          playAudio(assistantMessage.audioUrl!, completeHistory.length - 1)
        }, 500)
      }

      // æ£€æŸ¥å¯¹è¯æ˜¯å¦ç»“æŸï¼ˆç”±å¤§æ¨¡å‹åˆ¤æ–­å®Œæˆæˆ–è¾¾åˆ°æœ€å¤§è½®æ•°ï¼‰
      if (isEnd || nextRound >= maxRounds) {
        console.log('å¯¹è¯ç»“æŸï¼Œå¼€å§‹åˆ†ææµ‹è¯•ç»“æœ')
        if (isComplete) {
          console.log('å¯¹è¯ç›®æ ‡å·²å®Œæˆï¼Œè¿›è¡Œè´¨é‡è¯„æµ‹')
        } else if (nextRound >= maxRounds) {
          console.log('è¾¾åˆ°æœ€å¤§è½®æ•°ï¼Œå¼ºåˆ¶ç»“æŸå¯¹è¯')
        }
        await endTest()
      }
    } catch (err) {
      console.error('å¤„ç†è¯­éŸ³è¾“å…¥å¤±è´¥:', err)
      const errorMessage = err instanceof Error ? err.message : 'å¤„ç†è¾“å…¥å¤±è´¥ï¼Œè¯·é‡è¯•'
      alert(`GLM APIè°ƒç”¨å¤±è´¥: ${errorMessage}`)
      setError(errorMessage)
    } finally {
      setIsGeneratingResponse(false)
      console.log('=== è¯­éŸ³è¾“å…¥å¤„ç†å®Œæˆ ===')
    }
  }

  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(() => {
    if (recognition && !isRecording && !loading) {
      try {
        setIsRecording(true)
        setError('')
        recognition.start()

        setTimeout(() => {
          if (isRecording) {
            stopRecording()
          }
        }, 30000)
      } catch (err) {
        console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', err)
        setError('å¯åŠ¨å½•éŸ³å¤±è´¥ï¼Œè¯·é‡è¯•')
        setIsRecording(false)
      }
    }
  }, [recognition, isRecording, loading])

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(() => {
    if (recognition && isRecording) {
      try {
        recognition.stop()
        setIsRecording(false)
      } catch (err) {
        console.error('åœæ­¢å½•éŸ³å¤±è´¥:', err)
        setIsRecording(false)
      }
    }
  }, [recognition, isRecording])

  // æ’­æ”¾è¯­éŸ³
  const playAudio = (audioUrl: string, messageIndex: number) => {
    if (playingMessageIndex === messageIndex && audioElement) {
      audioElement.pause()
      setPlayingMessageIndex(null)
      setAudioElement(null)
      return
    }

    if (audioElement) {
      audioElement.pause()
    }

    const audio = new Audio(audioUrl)
    setAudioElement(audio)
    setPlayingMessageIndex(messageIndex)

    audio.play()

    audio.onended = () => {
      setPlayingMessageIndex(null)
      setAudioElement(null)
    }

    audio.onerror = () => {
      setPlayingMessageIndex(null)
      setAudioElement(null)
      setError('è¯­éŸ³æ’­æ”¾å¤±è´¥')
    }
  }

  // ç»“æŸæµ‹è¯•
  const endTest = async () => {
    setStatus('analyzing')
    setLoading(true)

    try {
      const currentMessages = messagesRef.current
      const currentRoundValue = currentRoundRef.current

      console.log('å¼€å§‹åˆ†ææµ‹è¯•ç»“æœ...')
      console.log('å¯¹è¯å†å²:', currentMessages)

      const analysisResponse = await fetch('/api/open-test/analyze', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          sceneId,
          testId,
          conversation: currentMessages,
          rounds: currentRoundValue
        })
      })

      if (!analysisResponse.ok) {
        const errorData = await analysisResponse.json()
        console.error('æµ‹è¯•åˆ†æ API è°ƒç”¨å¤±è´¥:', errorData)
        throw new Error(errorData.error || 'æµ‹è¯•åˆ†æ API è°ƒç”¨å¤±è´¥')
      }

      const analysisData = await analysisResponse.json()
      console.log('æµ‹è¯•åˆ†æç»“æœ:', analysisData)

      setStatus('completed')
      setShowAnalysis(true)
    } catch (err) {
      console.error('ç»“æŸæµ‹è¯•å¤±è´¥:', err)
      const errorMessage = err instanceof Error ? err.message : 'ç»“æŸæµ‹è¯•å¤±è´¥ï¼Œè¯·é‡è¯•'
      alert(`GLM APIè°ƒç”¨å¤±è´¥: ${errorMessage}`)
      setError(errorMessage)
      setStatus('active')
    } finally {
      setLoading(false)
    }
  }

  // æ¸²æŸ“ä¸åŒçŠ¶æ€çš„ç•Œé¢
  const renderContent = () => {
    switch (status) {
      case 'idle':
        const hasSpeechSupport = 'webkitSpeechRecognition' in window
        return (
          <div className="text-center py-12 px-6">
            <div className="w-16 h-16 mx-auto mb-6 rounded-full bg-gradient-to-r from-[#EC4899] to-[#F472B6] flex items-center justify-center shadow-lg">
              <i className="fas fa-comments text-white text-2xl"></i>
            </div>
            <h3 className="text-lg font-semibold text-[#1F2937] mb-4">å¼€æ”¾é¢˜æµ‹è¯•</h3>
            <div className="bg-white rounded-2xl shadow-sm border border-gray-100 p-4 mb-6">
              <p className="text-sm text-[#1F2937]">{testQuestion}</p>
            </div>
            <p className="text-sm text-[#6B7280] mb-8">
              æ‚¨å°†ä¸AIè¿›è¡Œ3è½®å¯¹è¯ï¼Œé€šè¿‡è¯­éŸ³å›ç­”é—®é¢˜
            </p>
            {!hasSpeechSupport && (
              <div className="bg-[#FFF8EE] border border-[#F59E0B]/20 rounded-2xl p-4 mb-8">
                <p className="text-sm text-[#92400E]">
                  <i className="fas fa-exclamation-triangle mr-2"></i>
                  æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨æ”¯æŒçš„æµè§ˆå™¨ï¼ˆå¦‚Chromeï¼‰
                </p>
              </div>
            )}
            <button
              className={`w-full py-4 rounded-2xl font-semibold text-sm transition-all ${hasSpeechSupport
                ? 'bg-gradient-to-r from-[#4F7CF0] to-[#7B5FE8] text-white shadow-md hover:shadow-lg'
                : 'bg-gray-200 text-gray-400 cursor-not-allowed'}`}
              onClick={analyzeQuestion}
              disabled={!hasSpeechSupport}
            >
              å¼€å§‹æµ‹è¯•
            </button>
          </div>
        )

      case 'analyzing':
        return (
          <AnalyzingView
            message="æ­£åœ¨åˆ†æé¢˜ç›®..."
            subMessage="AI æ­£åœ¨ç†è§£åœºæ™¯ã€è§’è‰²å’Œå¯¹è¯ç›®æ ‡"
          />
        )

      case 'role-selection':
        return (
          <RoleSelectionView
            questionAnalysis={questionAnalysis}
            selectedRole={selectedRole}
            difficultyLevel={difficultyLevel}
            voiceEnabled={voiceEnabled}
            error={error}
            sceneName={testQuestion}
            onSelectRole={setSelectedRole}
            onSelectDifficulty={setDifficultyLevel}
            onToggleVoice={() => setVoiceEnabled(!voiceEnabled)}
            onConfirm={confirmRoleAndDifficulty}
          />
        )

      case 'initializing':
        return (
          <InitializingView
            message="æ­£åœ¨åˆå§‹åŒ–å¯¹è¯..."
            subMessage="AI æ­£åœ¨å‡†å¤‡è§’è‰²å’Œåœºæ™¯è®¾ç½®"
          />
        )

      case 'active':
        return (
          <ActiveChatView
            messages={messages}
            currentRound={currentRound}
            maxRounds={maxRounds}
            isRecording={isRecording}
            isGeneratingResponse={isGeneratingResponse}
            playingMessageIndex={playingMessageIndex}
            error={error}
            onStartRecording={startRecording}
            onStopRecording={stopRecording}
            onPlayAudio={playAudio}
            onSendText={handleVoiceInput}
            messagesEndRef={messagesEndRef}
          />
        )

      case 'completed':
        return (
          <AnimatePresence mode="wait">
            {showAnalysis ? (
              <TestAnalysis
                sceneId={sceneId}
                testId={testId}
                conversation={messages}
                rounds={currentRound}
                onComplete={onComplete}
              />
            ) : (
              <CompletedView
                currentRound={currentRound}
                sceneId={sceneId}
                testId={testId}
                messages={messages}
                onViewAnalysis={() => setShowAnalysis(true)}
                onComplete={onComplete}
              />
            )}
          </AnimatePresence>
        )

      default:
        return null
    }
  }

  return (
    <div className="w-full h-full flex flex-col">
      {renderContent()}
    </div>
  )
}
